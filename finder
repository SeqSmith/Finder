#! /usr/bin/env python
######################################################################################################################################################################################
#  Version 1.6
#  Developed by Sagnik Banerjee

# Highlights of version 5
####################################################################################
# Functionalities included from previous analysis
# Read error correction using Rcorrector [Omitted was taking a very long time to finish]
# Multiple rounds of mapping to ensure most optimized alignment
# PsiCLASS executed on each project separately
# Functions to check if low coverage splices are being retained by PsiCLASS
# GTF files from each project merged with StringTie-merge
####################################################################################
#
# # Highlights of version 6
####################################################################################
# Metadata datastructure changed to bioproject->Run from Run->bioproject
# STAR alignments modified (--outSAMattrRGline added)
# Latest version of PsiCLASS used
# rpy2 used instead of writing to disk for CPD
# Data structures modified for CPD detection
# Logging introduced for easier error detection
# Software dependencies coded into options.mrna_md
####################################################################################
######################################################################################################################################################################################

from argparse import RawTextHelpFormatter
from builtins import enumerate, list
from collections import OrderedDict
from copy import deepcopy
from itertools import groupby
from operator import itemgetter
from pathlib import Path
from scripts.alignReads import *
from scripts.determineOptimalStartingPoint import *
from scripts.fileReadWriteOperations import *
from scripts.findGenesFromExpression import *
from scripts.findTranscriptsInEachSampleNotReportedInCombinedAnnotations import *
from scripts.fixOverlappingAndMergedTranscripts import *
from scripts.fixTranscriptsConnectingTwoTranscripts import *
from scripts.generateGenomicAndTranscriptomicCounts import *
from scripts.mergeCloselySpacedTranscripts import *
from scripts.performAssembly import *
from scripts.predictCDS import *
from scripts.predictGenesUsingBRAKER import *
from scripts.removeRedundantTranscripts import *
from scripts.removeSpuriousTranscriptsBasedOnCDS import *
from scripts.runCommand import *
from scripts.splitTranscriptsWithQuestionableSpliceJunctions import *
from scripts.transcriptToConditions import *
import argparse
import collections
import copy
import glob
import importlib
import itertools
import math
import multiprocessing
import os
import pickle
import pprint
import random
import re
import statistics
import subprocess
import sys
import time

from ruffus.proxy_logger import *

import numpy as np
import pandas as pd


def parseCommandLineArguments():
    parser = argparse.ArgumentParser(prog="finder",description="Generates gene annotation from RNA-Seq data",formatter_class=RawTextHelpFormatter)
    requiredNamed = parser.add_argument_group('Required arguments')
    optionalNamed = parser.add_argument_group('Optional arguments')
    
    # Mandatory arguments
    requiredNamed.add_argument("--metadatafile","-mf",help="Please enter the name of the metadata file. Enter 0 in the last column of those samples which you wish to skip processing. The columns should represent the following in order --> BioProject, SRA Accession, Tissues, Description, Date, Read Length, Ended (PE or SE), RNA-Seq, process, Location. If the sample is skipped it will not be downloaded. Leave the directory path blank if you are downloading the samples. In the end of the run the program will output a csv file with the directory path filled out. Please check the provided csv file for more information on how to configure the metadata file. ",required=True)
    requiredNamed.add_argument("--output_directory","-out_dir",help="Enter the name of the directory where all other operations will be performed",required=True)
    requiredNamed.add_argument("--genome","-g",help="Enter the SOFT-MASKED genome file of the organism",required=True)
    
    # Optional arguments
    optionalNamed.add_argument("--cpu","-n",help="Enter the number of CPUs to be used.",default=1)
    optionalNamed.add_argument("--genome_dir_star","-gdir_star",help="Please enter the location of the genome index directory of STAR")
    optionalNamed.add_argument("--genome_dir_olego","-gdir_olego",help="Please enter the location of the genome index directory of OLego")    
    optionalNamed.add_argument("--verbose","-verb",default=1,help="Enter a verbosity level")
    optionalNamed.add_argument("--protein","-p",help="Enter the protein fasta")
    optionalNamed.add_argument("--no_cleanup","-no_cleanup",help="Provide this option if you do not wish to remove any intermediate files. Please note that this will NOT remove any files and might take up a large amount of space",action="store_true")
    optionalNamed.add_argument("--preserve_raw_input_data","-preserve",help="Set this argument if you want to preserve the raw fastq files. All other temporary files will be removed. These fastq files can be later used. ",action="store_true")
    optionalNamed.add_argument("--checkpoint","-c",help="""Enter a value if you wish to restart operations from a certain check point. Please note if you have new RNA-Seq samples, then FINDER will override this argument and computation will take place from read alignment. If there are missing data in any step then also FINDER will enforce restart of operations from a previous checkpoint. For example, if you wish to run assembly on samples for which alignments are not available then FINDER will readjust this value and set it to 1.
    1. Align reads to reference genome (Will trigger removal of all alignments and start from beginning)
    2. Assemble with PsiCLASS (Will remove all assemblies) 
    3. Find genes with FINDER (entails changepoint detection) 
    4. Predict genes using BRAKER2 (Will remove previous results of gene predictions with BRAKER2)
    5. Annotate coding regions
    6. Merge FINDER annotations with BRAKER2 predictions and protein sequences
    """,default = None,type =int)
    #optionalNamed.add_argument("--intron_gff3","-intron_gff3",help="Enter the name and location of the file containing introns in gff3 format")
    #optionalNamed.add_argument("--ground_truth_gtf","-gt_gtf",help="Enter the gtf filename of the actual annotation [for developmental purposes]")
    #optionalNamed.add_argument("--error_correct_reads","-ecr",help="Set this argument if you wish to perform error corrections using Rcorrector. Please note that setting this option does not guarantee correction. Short read error correction is a time consuming task. Hence, only those samples will be error corrected which have a low mapping rate. Please refer to page no. <> of the manual for more details. ",action="store_true")
    
    # Suppressed arguments
    parser.add_argument("--md","-md",help=argparse.SUPPRESS)# Metadata to store all the requested processing
    #parser.add_argument("--output_trimmomatic","-output_trimmomatic",help=argparse.SUPPRESS) # Output directory for adapter removed files
    parser.add_argument("--output_rcorrector","-output_rcorrector",help=argparse.SUPPRESS) # Output directory for Rcorrector outputs
    parser.add_argument("--output_star","-ostar",help=argparse.SUPPRESS)# Output of STAR alignments
    parser.add_argument("--raw_data_downloaded_from_NCBI","-raw_data_downloaded_from_NCBI",help=argparse.SUPPRESS)# New directory is created if no fastq file is provided as input
    parser.add_argument("--output_assemblies_psiclass_terminal_exon_length_modified","-output_assemblies_psiclass_terminal_exon_length_modified",help=argparse.SUPPRESS)
    #parser.add_argument("--output_logs","-ologs",help=argparse.SUPPRESS)# Directory for logs
    #parser.add_argument("--sample_wide_merge","-sample_wide_merge",help=argparse.SUPPRESS)# Directory to hold gtf files merged from each bioproject
    parser.add_argument("--record_time",help=argparse.SUPPRESS)# Holds duration of execution for each step of execution
    parser.add_argument("--output_fasta_N_removed",help=argparse.SUPPRESS) # Directory to contain fastq files after each sequence is cleaned of flanking Ns
    parser.add_argument("--output_sample_fastq",help=argparse.SUPPRESS)# Directory to hold fastq files generated by sampling original fastq to decide whether or not to error correct
    parser.add_argument("--error_corrected_raw_data",help=argparse.SUPPRESS)# Directory to hold Rcorrector error corrected fastq
    parser.add_argument("--softwares",help=argparse.SUPPRESS)# Sets up the full path to the dependent softwares like STAR, Spring, etc
    parser.add_argument("--temp_dir",help=argparse.SUPPRESS)# Directory to store temporary information
    parser.add_argument("--compressed_data_files",help=argparse.SUPPRESS)# Directory to store compressed read files using SPRING
    parser.add_argument("--indices",help=argparse.SUPPRESS)# Directory to store the indices for STAR and bowtie2
    parser.add_argument("--output_braker",help=argparse.SUPPRESS)# Directory to store the BRAKER output
    parser.add_argument("--total_space",help=argparse.SUPPRESS)# Records the total space occupied by files
    parser.add_argument("--space_saved",help=argparse.SUPPRESS)# Records the amount of space saved after moving intermediate files
    parser.add_argument("--single_end_adapterfile",help=argparse.SUPPRESS)
    parser.add_argument("--paired_end_adapterfile",help=argparse.SUPPRESS)
    parser.add_argument("--files_for_ncrna",help=argparse.SUPPRESS)
    
    return parser.parse_args()

def validateCommandLineArguments(options,logger_proxy,logging_mutex):
    #options.output_trimmomatic=options.output_directory+"/trimmomatic_output"
    options.output_star=options.output_directory+"/alignments"
    options.output_assemblies_psiclass_terminal_exon_length_modified=options.output_directory+"/assemblies_psiclass_modified"
    #soptions.output_logs=options.output_directory+"/logs"
    #options.output_rcorrector=options.output_directory+"/error_corrected"
    options.output_fasta_N_removed=options.output_directory+"/raw_fasta_N_removed"
    #options.output_sample_fastq=options.output_directory+"/sample_fastq"
    options.error_corrected_raw_data=options.output_directory+"/raw_data_error_corrected"
    options.temp_dir=options.output_directory+"/temp"
    options.raw_data_downloaded_from_NCBI=options.output_directory+"/raw_data_downloaded_from_NCBI"
    #options.compressed_data_files=options.output_directory+"/compressed_data_files"
    options.indices=options.output_directory+"/indices"
    options.output_braker=options.output_directory+"/braker"
    options.final_GTF_files = options.output_directory+"/final_GTF_files"
    options.verbose=int(options.verbose) if int(options.verbose)<=3 else 3
    options.softwares={}
    options.files_for_ncrna={}
    #options.ncrna_dir=options.output_directory+"/ncrna"
    
    os.system("mkdir -p "+options.output_directory)
    os.system("mkdir -p "+options.output_star)
    os.system("mkdir -p "+options.output_assemblies_psiclass_terminal_exon_length_modified)
    os.system("mkdir -p "+options.temp_dir)
    os.system("mkdir -p "+options.raw_data_downloaded_from_NCBI)
    os.system("mkdir -p "+options.indices)
    os.system("mkdir -p "+options.final_GTF_files)
    #os.system("mkdir -p "+options.output_fasta_N_removed)
    #os.system("rm -rf "+options.output_sample_fastq)
    #os.system("mkdir -p "+options.output_sample_fastq)
    #os.system("rm -rf "+options.error_corrected_raw_data)
    #os.system("mkdir -p "+options.error_corrected_raw_data)
    #os.system("mkdir -p "+options.compressed_data_files)
    #os.system("mkdir -p "+options.output_trimmomatic)
    #os.system("mkdir -p "+options.output_logs)
    #os.system("mkdir -p "+options.output_rcorrector)
    #os.system("mkdir -p "+options.ncrna_dir)
    
    ########################################################################################################
    # Setting up links to the softwares
    ########################################################################################################
    cmd="whereis finder > "+options.temp_dir+"/finding_finder"
    os.system(cmd)
    finder_directory=open(options.temp_dir+"/finding_finder","r").read().split(":")[-1].strip()
    if finder_directory!="":
        # PATH NOT set to downloaded directory
        dep_path="/".join(finder_directory.split("/")[:-1])+"/dep"
    else:
        # PATH IS set to downloaded directory
        if "/" in sys.argv[0]:
            dep_path="/".join(sys.argv[0].split("/")[:-1])+"/dep"
        else:
            dep_path="dep"

    options.softwares["psiclass"]=dep_path+"/psiclass_terminal_exon_length_modified/psiclass"
    options.softwares["junc"]=dep_path+"/psiclass_terminal_exon_length_modified//junc"
    options.softwares["subexon-info"]=dep_path+"/psiclass_terminal_exon_length_modified//subexon-info"
    options.softwares["addXS"]=dep_path+"/psiclass_terminal_exon_length_modified//addXS"
    options.softwares["fastq-sample"]=dep_path+"/fastq-tools-0.8/scripts/fastq-sample"
    options.softwares["download_and_dump_fastq_from_SRA"]=dep_path+"/../utils/downloadAndDumpFastqFromSRA.py"
    options.softwares["transferGenomicNucleotideCountsToTranscriptome"]=dep_path+"/../scripts/transferGenomicNucleotideCountsToTranscriptome.py"
    options.softwares["find_exonic_troughs"]=dep_path+"/../scripts/find_exonic_troughs.R"
    options.softwares["olego"]=dep_path+"/olego/olego"
    options.softwares["olegoindex"]=dep_path+"/olego/olegoindex"
    options.softwares["mergePEsam.pl"]=dep_path+"/olego/mergePEsam.pl"
    options.softwares["xa2multi"]=dep_path+"/olego/xa2multi.pl"
    options.softwares["gmst"]=dep_path+"/gmst.pl"
    options.softwares["prodigal"]=dep_path+"/Prodigal/prodigal"
    options.softwares["canon-gff3"]=dep_path+"/canon-gff3"
    options.softwares["convert_exonerate_gff_to_gtf"] = dep_path+"/../utils/convert_exonerate_gff_to_gtf.py"
    
    ################################################################################
    # Set paths for BRAKER run
    ################################################################################
    options.softwares["augustus_main_dir"]=dep_path+"/Augustus"
    options.softwares["braker"]=dep_path+"/BRAKER/scripts/braker.pl"
    options.softwares["GENEMARK_PATH"]=dep_path+"/gmes_linux_64"
    options.softwares["AUGUSTUS_CONFIG_PATH"]=options.output_braker+"/Augustus/config"
    options.softwares["AUGUSTUS_BIN_PATH"]=options.output_braker+"/Augustus/bin"
    options.softwares["AUGUSTUS_SCRIPTS_PATH"]=options.output_braker+"/Augustus/scripts"
    options.softwares["GUSHR_PATH"]=dep_path+"/GUSHR"
    os.environ["PATH"] = os.environ["PATH"]+":/"+dep_path
    os.environ["AUGUSTUS_CONFIG_PATH"] = options.output_braker+"/Augustus/config"
    os.environ["AUGUSTUS_BIN_PATH"]=options.output_braker+"/Augustus/bin"
    os.environ["AUGUSTUS_SCRIPTS_PATH"]=options.output_braker+"/Augustus/scripts"
    with logging_mutex:
        logger_proxy.info("Software paths have been set")
    
    options.record_time={}
    cmd="samtools "+" faidx "+options.genome
    os.system(cmd)
    
    if options.genome_dir_star is None:
        with logging_mutex:
            logger_proxy.info("Generating STAR index")
        options.genome_dir_star=options.indices+"/star_index_without_transcriptome"
        os.system("mkdir -p "+options.genome_dir_star)
        cmd="STAR "
        cmd+=" --runThreadN "+options.cpu
        cmd+=" --runMode genomeGenerate "
        cmd+=" --genomeDir "+options.genome_dir_star
        cmd+=" --genomeFastaFiles "+options.genome
        cmd+=" > "+options.genome_dir_star+".output "
        cmd+=" 2> "+options.genome_dir_star+".error "
        os.system(cmd)
        with logging_mutex:
            logger_proxy.info("STAR index generation complete")
    
    if options.genome_dir_olego is None:  
        with logging_mutex:
            logger_proxy.info("Generating OLego index")
        cmd=options.softwares["olegoindex"]
        cmd+=" -p "+options.indices+"/olego_index "
        cmd+=options.genome
        cmd+=" > "+options.indices+"_olego_index.output "
        cmd+=" 2> "+options.indices+"_olego_index.error "
        os.system(cmd)
        options.genome_dir_olego=options.indices+"/olego_index"
        
        with logging_mutex:
            logger_proxy.info("OLego index built")
    
    """if os.path.exists(options.indices+"/bowtie_index.rev.1.ebwt")==False:
        cmd="bowtie-build "
        cmd+=" "+options.genome
        cmd+=" "+options.indices+"/bowtie_index "
        os.system(cmd)"""
    
    ################################################################################
    # Set up main files for ncRNA computation
    ################################################################################
    options.files_for_ncrna["mature_ATGC"]=dep_path+"/mature_ATGC.fa"
    
def isKthBitSet(n, k):
    """
    isKthBitSet(16,5) = True
    isKthBitSet(256,5) = False
    isKthBitSet(272,5) = True
    reverse==>true, forward==>False
    """ 
    if n & (1 << (k - 1)): 
        return True 
    else: 
        return False 
     
def readValidSJDBInfo(valid_SJDB_filename):
    """
    """
    validSJDB={}
    fhr=open(valid_SJDB_filename,"r")
    for line in fhr:
        chromosome,start,end=line.strip().split()[:3]
        if chromosome not in validSJDB:
            validSJDB[chromosome]=[]
        validSJDB[chromosome].append(start+"_"+end)
    fhr.close()
    for chromosome in validSJDB:
        validSJDB[chromosome]=set(validSJDB[chromosome])
    return validSJDB

def removeSpuriousMappingsInParallel(eachinput):
    """
    """
    samfilename,outputsamfilename,validSJDB,logging_mutex,logger_proxy,Run=eachinput
    fhr=open(samfilename,"r")
    fhw=open(outputsamfilename,"w")
    for line in fhr:
        if line[0]=="@":
            fhw.write(line)
        else:
            if "N" not in line.strip().split()[5]:
                fhw.write(line)
            else:
                chromosome=line.split()[2]
                for ele in line.split():
                    if "jI:B:i," in ele:    
                        coordinates=ele.split("jI:B:i,")[-1]
                        break
                coordinates=coordinates.split(",")
                i=0
                skip=0
                while i<len(coordinates):
                    junction_start,junction_end=coordinates[i],coordinates[i+1]
                    if chromosome in validSJDB and junction_start+"_"+junction_end not in validSJDB[chromosome]:
                        skip=1
                    i+=2
                if skip==0:
                    fhw.write(line)
    fhw.close()
    fhr.close()
    with logging_mutex:
        logger_proxy.info("Removal of spurious alignments completed for run --> "+Run)

def removeIandD(cigar):
    
    cigar_values=[int(s) for s in re.findall(r'\d+',cigar)]
    cigar_alphabets=re.findall(r'[A-Z]',cigar)
    
    new_cigar_values=[]
    new_cigar_alphabets=[]
    skip_next=0
    for num,alphabet in enumerate(cigar_alphabets):
        if skip_next==1:
            skip_next=0
            continue
        if alphabet=="I" or alphabet=="D":
            new_cigar_values[-1]+=cigar_values[num+1]
            skip_next=1
        else:
            new_cigar_alphabets.append(alphabet) 
            new_cigar_values.append(cigar_values[num])
    new_cigar=""
    for j in range(len(new_cigar_values)):
        new_cigar+=str(new_cigar_values[j])+str(new_cigar_alphabets[j])
    return new_cigar
    
def removeSpliceJunctionsWithLowEntropyInParallel(eachinput):
    samfilename,dummy=eachinput
    # Construct splice junction database
    sjdb={} 
    fhr=open(samfilename,"r")
    for line in fhr:
        if line[0]=="@":continue
        line=line.strip().split("\t")
        if "N" not in line[5]:continue
        chromosome=line[2]
        if chromosome not in sjdb:
            sjdb[chromosome]={}
        cigar=line[5]
        if "I" in cigar or "D" in cigar:
            """print("Prev",cigar)
            cigar=removeIandD(cigar)
            print("Next",cigar)
            sys.stdout.flush()"""
        cigar_values=[int(s) for s in re.findall(r'\d+',cigar)]
        cigar_alphabets=re.findall(r'[A-Z]',cigar)
        
        # Find the splice junctions
        splice_junctions_in_this_alignment=[]
        i=0
        while i<len(line[18].split("jI:B:i,")[-1].split(",")):
            splice_junctions_in_this_alignment.append([line[18].split("jI:B:i,")[-1].split(",")[i],line[18].split("jI:B:i,")[-1].split(",")[i+1]])
            i+=2
        
        for junction_num,each_splice_junction in enumerate(splice_junctions_in_this_alignment):
            splice_junction=each_splice_junction[0]+"_"+each_splice_junction[1]
            if splice_junction not in sjdb[chromosome]:
                sjdb[chromosome][splice_junction]={"left_overhang":{},"right_overhang":{},"total_reads":0}
            sjdb[chromosome][splice_junction]["total_reads"]+=1
            
            left_overhang=cigar_values[2*junction_num]
            right_overhang=cigar_values[2*junction_num+2]
            
            if left_overhang not in sjdb[chromosome][splice_junction]["left_overhang"]:
                sjdb[chromosome][splice_junction]["left_overhang"][left_overhang]=0
            sjdb[chromosome][splice_junction]["left_overhang"][left_overhang]+=1
            
            if right_overhang not in sjdb[chromosome][splice_junction]["right_overhang"]:
                sjdb[chromosome][splice_junction]["right_overhang"][right_overhang]=0
            sjdb[chromosome][splice_junction]["right_overhang"][right_overhang]+=1
    fhr.close()
    
    # Compute entropies
    for chromosome in sjdb:
        for splice_junction in sjdb[chromosome]:
            left_entropy=0
            right_entropy=0
            total_reads=sjdb[chromosome][splice_junction]["total_reads"]
            
            for left_offset in sjdb[chromosome][splice_junction]["left_overhang"]:
                p=sjdb[chromosome][splice_junction]["left_overhang"][left_offset]/total_reads
                left_entropy=-p*math.log2(p)
                
            for right_offset in sjdb[chromosome][splice_junction]["right_overhang"]:
                p=sjdb[chromosome][splice_junction]["right_overhang"][right_offset]/total_reads
                right_entropy=-p*math.log2(p)
            
            list(map(int,splice_junction.split("_")))
            #print(chromosome+":"+"-".join(splice_junction.split("_")),math.abs(),left_entropy,right_entropy,sum(sjdb[chromosome][splice_junction]["left_overhang"].values()),sum(sjdb[chromosome][splice_junction]["right_overhang"].values()),total_reads)
            sys.stdout.flush()

def removeSpuriousMappings(options,cpu_per_condition,logging_mutex,logger_proxy):
    pool = multiprocessing.Pool(processes=int(options.cpu))    
    allinputs=[]
    for condition in options.mrna_md:
        for Run in options.mrna_md[condition]:
            if os.path.exists(options.output_star+"/"+Run+"_final.sortedByCoord.out.sam")==True:continue
            cmd="samtools "+" view -@ "+str(cpu_per_condition)
            cmd+=" -h "+options.output_star+"/"+Run+"_final.sortedByCoord.out.bam > "
            cmd+=options.output_star+"/"+Run+"_final.sortedByCoord.out.sam"
            allinputs.append(["dummy",cmd])
    pool.map(runCommand,allinputs)

    
    """# Reads the samfile and selects the correct splice junctions 
    pool = multiprocessing.Pool(processes=int(options.cpu))
    allinputs=[]
    for bioproject in bioproject_to_run:
        for Run in bioproject_to_run[bioproject]:
            samfilename=options.output_star+"/"+Run+"_final.sortedByCoord.out.sam"
            #outputsamfilename=options.output_star+"/"+Run+"_final.sortedByCoord.out.sam.splices_with_low_entropy_removed"
            allinputs.append([samfilename,"dummy"])
    pool.map(removeSpliceJunctionsWithLowEntropyInParallel,allinputs)    
    """
    
    pool = multiprocessing.Pool(processes=int(options.cpu))
    allinputs=[]
    for condition in options.mrna_md:
        valid_SJDB_filename=options.output_star+"/"+condition+"_round1_and_round2_and_round3_and_round4_SJ.out.tab"
        validSJDB=readValidSJDBInfo(valid_SJDB_filename)
        for Run in options.mrna_md[condition]:
            samfilename=options.output_star+"/"+Run+"_final.sortedByCoord.out.sam"
            outputsamfilename=options.output_star+"/"+Run+"_final.sortedByCoord.out.sam.new"
            allinputs.append([samfilename,outputsamfilename,validSJDB,logging_mutex,logger_proxy,Run])
    pool.map(removeSpuriousMappingsInParallel,allinputs)
    
    allinputs=[]
    for condition in options.mrna_md:
        for Run in options.mrna_md[condition]:
            cmd="samtools "+" view -@ "+str(cpu_per_condition)+"  "
            cmd+="-Sbh "+options.output_star+"/"+Run+"_final.sortedByCoord.out.sam.new > "
            cmd+=options.output_star+"/"+Run+"_final.sortedByCoord.out.bam"
            allinputs.append([Run,cmd])
    pool.map(runCommand,allinputs)
    
    allinputs=[]
    for condition in options.mrna_md:
        for Run in options.mrna_md[condition]:
            cmd="rm "+options.output_star+"/"+Run+"_final.sortedByCoord.out.sam* "
            allinputs.append([Run,cmd])
    pool.map(runCommand,allinputs)
                      
def configureLogger(options):
    os.system("mkdir -p "+options.output_directory)
    os.system("rm -f "+options.output_directory+"/progress.log")
    
    arguments={}
    arguments["file_name"]=options.output_directory+"/progress.log"
    arguments["formatter"] = "%(asctime)s - %(name)s - %(levelname)6s - %(message)s"
    arguments["level"]     = logging.DEBUG
    arguments["delay"]     = False
    
    (logger_proxy,logging_mutex) = make_shared_logger_and_proxy (setup_std_shared_logger,"FINDER", arguments)
    
    return logger_proxy,logging_mutex
                   
def orchestrateGeneModelPrediction(options,logger_proxy,logging_mutex):
    
    #########################################################################################################
    # Use STAR and OLego to align short reads
    #########################################################################################################
    alignReadsAndMergeOutput(options,logger_proxy,logging_mutex)
    
    #########################################################################################################
    # Rearrange data for assembly
    #########################################################################################################
    reArrangeDataForAssembly(options,logger_proxy,logging_mutex)

    #########################################################################################################
    # Collect information about mapping
    #########################################################################################################
    collectStatsAboutMapping(options)
    with logging_mutex:
        logger_proxy.info("Information collection about alignments completed ")
    
    #########################################################################################################
    # Generate one assembly with all samples
    #########################################################################################################
    all_runs=[os.path.exists(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/psiclass_output_sample_"+Run+".gtf") for condition in options.mrna_md for Run in options.mrna_md[condition]]
    if False in all_runs or os.path.exists(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined.gtf")==False:
        runPsiCLASSMaxTerminalExonLength(options,logging_mutex,logger_proxy)
        with logging_mutex:
            logger_proxy.info("Generation of assemblies with PsiCLASS completed ")
    else:
        with logging_mutex:
            logger_proxy.info("Skipping the regeneration of assemblies with PsiCLASS ")
    
    #########################################################################################################
    # Select transcripts expressed in tissue but not reported in combined.gtf file 
    #########################################################################################################
    findTranscriptsInEachSampleNotReportedInCombinedAnnotations(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("Missed tissue specific transcripts added to gene annotations ")
    
    #########################################################################################################
    # Remove redundant transcripts which are proper subsets of other transcripts
    #########################################################################################################
    input_gtf_filename=options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_missed_transcripts_added.gtf"
    output_gtf_filename=options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_redundant_transcripts_removed.gtf"
    removeRedundantTranscripts(input_gtf_filename,output_gtf_filename,options)
    with logging_mutex:
        logger_proxy.info("Redundant transcripts removed from gene annotations ")
    
    #########################################################################################################
    # Find transcripts formed due to read alignments in incorrect direction 
    #########################################################################################################
    fixTranscriptsConnectingTwoTranscripts(options,logging_mutex,logger_proxy) # Currently a dummy implementation
    with logging_mutex:
        logger_proxy.info("Transcripts connecting two other transcripts in opposite direction fixed ")     
    
    #########################################################################################################
    # Generate counts for the generated transcriptome
    #########################################################################################################
    generateGenomicAndTranscriptomicCounts(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("Generation of transcriptomic counts completed ")
    
    #########################################################################################################
    # Fix overlapping and merged transcripts
    #########################################################################################################
    fixOverlappingAndMergedTranscripts(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("Fix overlapping and merged transcripts completed")
    
    #########################################################################################################
    # Remove redundant transcripts which are proper subsets of other transcripts
    #########################################################################################################
    input_gtf_filename=options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_cov_opp_split.gtf"
    output_gtf_filename=options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_cov_opp_split_redundancy_removed.gtf"
    removeRedundantTranscripts(input_gtf_filename,output_gtf_filename,options)
    with logging_mutex:
        logger_proxy.info("Redundant transcripts removed from gene annotations ")
    
    #########################################################################################################
    # Find closely placed almost overlapping transcripts transcripts 
    #########################################################################################################
    mergeCloselySpacedTranscripts(options)
    with logging_mutex:
        logger_proxy.info("Closely placed transcripts with very similar expression level merged")
    
    #########################################################################################################
    # Split transcripts with splice junctions NOT present *.tab file
    #########################################################################################################
    splitTranscriptsWithQuestionableSpliceJunctions(options)
    with logging_mutex:
        logger_proxy.info("Transcripts splited on intron information")
    
    #########################################################################################################
    # Remove redundant transcripts which are proper subsets of other transcripts
    #########################################################################################################
    input_gtf_filename=options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ.gtf"
    output_gtf_filename=options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed.gtf"
    removeRedundantTranscripts(input_gtf_filename,output_gtf_filename,options)
    with logging_mutex:
        logger_proxy.info("Redundant transcripts removed from gene annotations ")
    
    #########################################################################################################
    # Append tissue/condition expressed in information to each transcript  
    #########################################################################################################
    transcriptToConditions(options)
    with logging_mutex:
        logger_proxy.info("Associating transcripts to conditions completed")
          
def splitGeneModelsUsingBRAKERPredictions(options,logger_proxy,logging_mutex):
    """
    """
    #########################################################################################################################################
    # Split transcripts if BRAKER predicted a CDS in the UTRs of FINDER predictions
    #########################################################################################################################################
    braker_gtf_file=options.output_assemblies_psiclass_terminal_exon_length_modified+"/braker.gtf"
    psiclass_gtf_file=options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed.gtf"
    
    
    # Fix direction of uniexon transcripts
    fhr=open(psiclass_gtf_file,"r")
    gene_to_direction={}
    for line in fhr:
        line=line.strip().split("\t")
        if line[2]!="transcript":continue
        gene_id=line[8].split("gene_id")[-1].split(";")[0].strip().strip("\"")
        #print(gene_id)
        direction=line[6]
        if gene_id not in gene_to_direction and direction!=".":
            gene_to_direction[gene_id]=direction
    #pprint.pprint(gene_to_direction)
    fhr.close()
    
    fhr=open(psiclass_gtf_file,"r")
    fhw=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed.gtf","w")
    for line in fhr:
        line=line.strip().split("\t")
        gene_id=line[8].split("gene_id")[-1].split(";")[0].strip().strip("\"")
        if gene_id in gene_to_direction:
            line[6]=gene_to_direction[gene_id]
        fhw.write("\t".join(line)+"\n")
    
    fhw.close()
    fhr.close()
    
    cmd="gt gtf_to_gff3 "
    cmd+=" <(cat "+options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed.gtf"
    cmd+="|awk -vOFS=\"\t\" -F\"\t\" '$8=\".\"' "
    cmd+=")"
    cmd+="|sed 's/FPKM/fpkm/g'|sed 's/TPM/tpm/g'|gt gff3 -sort yes -retainids yes -tidy yes|"
    cmd+=options.softwares["canon-gff3"]
    cmd+=" > "+options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed.gff3 2> /dev/null"
    subprocess.check_call(['bash', '-c', cmd])
    
    fhr=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed.gff3","r")
    fhw=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed_only_UTR.gtf","w")
    for line in fhr:
        if line[0]=="#":
            #fhw.write(line)
            continue
        if line.strip().split("\t")[2]=="gene" or line.strip().split("\t")[2]=="mRNA":
            #fhw.write(line)
            if line.strip().split("\t")[2]=="mRNA":
                mRNA_def=";".join(line.strip().split("\t")[-1].split(";")[2:])
                for ele in mRNA_def.split(";"):
                    if "gene_id" in ele:
                        gene_id=ele.split("gene_id=")[-1]
                    if "transcript_id" in ele:
                        transcript_id_num=ele.split("transcript_id=")[-1].split(".")[-1]
        if line.strip().split("\t")[2]=="five_prime_UTR":
            #line=line.strip()+";"+mRNA_def
            line=line.split("\t")
            line[2]="exon"
            line[-1]="transcript_id \""+gene_id+"_5_prime_UTR."+transcript_id_num+"\"; gene_id \""+gene_id+"_5_prime_UTR\""
            line="\t".join(line)
            
            fhw.write(line+"\n")
            
        if line.strip().split("\t")[2]=="three_prime_UTR":
            #line=line.strip()+";"+mRNA_def
            line=line.split("\t")
            line[2]="exon"
            line[-1]="transcript_id \""+gene_id+"_3_prime_UTR."+transcript_id_num+"\"; gene_id \""+gene_id+"_3_prime_UTR\""
            line="\t".join(line)
            fhw.write(line+"\n")
    fhw.close()
    fhr.close()
    
    cmd="mikado compare "
    cmd+=" -r "+options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed_only_UTR.gtf"
    cmd+=" -p "+braker_gtf_file
    cmd+=" -o "+options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/braker_in_finder_UTRs_mikado"
    cmd+=" -erm "
    os.system(cmd)
    
    
    braker_transcripts=[]
    finder_transcripts=[]
    fhr=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/braker_in_finder_UTRs_mikado.refmap","r")
    for line in fhr:
        finder_transcript,ccode,braker_transcript=line.strip().split("\t")[:3]
        if ccode=="=" or ccode=="_":
            braker_transcripts.append(braker_transcript)
            finder_transcripts.append(finder_transcript)
    fhr.close()
    
    fhr=open(braker_gtf_file,"r")
    fhw=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/braker_to_modify_finder_whole_transcript.gtf","w")
    fhw_CDS=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/braker_to_modify_finder_CDS.gtf","w")
    
    for line in fhr:
        if line.strip().split("\t")[2]=="transcript":continue
        if line.strip().split("transcript_id")[-1].split(";")[0].strip().strip("\"") in braker_transcripts:
            fhw.write(line)
            if line.strip().split("\t")[2]=="CDS":
                fhw_CDS.write(line)
    fhr.close()
    fhw.close()
    fhw_CDS.close()
    
    #print(finder_transcripts)
    finder_transcript_modified=[]
    for transcript in finder_transcripts:
        if "_5_prime_UTR" in transcript:
            finder_transcript_modified.append(transcript.replace("_5_prime_UTR",''))
            #print(transcript.replace("_5_prime_UTR",''))
        if "_3_prime_UTR" in transcript:
            finder_transcript_modified.append(transcript.replace("_3_prime_UTR",''))
            #print(transcript.replace("_3_prime_UTR",''))
    finder_transcripts=finder_transcript_modified
    #print(finder_transcripts)
    fhr=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed.gtf","r")
    fhw=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed_to_modify_finder_whole_transcript.gtf","w")
    fhw_CDS=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined_split_transcripts_with_bad_SJ_redundancy_removed_direction_fixed_to_modify_finder_CDS.gtf","w")
    for line in fhr:
        if line.strip().split("\t")[2]=="transcript":continue
        if line.strip().split("transcript_id")[-1].split(";")[0].strip().strip("\"") in finder_transcripts:
            fhw.write(line)
            if line.strip().split("\t")[2]=="CDS":
                fhw_CDS.write(line)
        
    fhr.close()
    fhw.close()
    fhw_CDS.close()
    
    combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript=readAllTranscriptsFromGTFFileInParallel([options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript.gtf","dummy","dummy"])[0]
    temp={}
    for chromosome in combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript:
        for transcript_id in combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript[chromosome]:
            temp[transcript_id]=combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript[chromosome][transcript_id]
    combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript=temp
    
    fhw_first_and_last_exon=open(options.output_assemblies_psiclass_terminal_exon_length_modified+"/finder_first_and_last_exon_point.gtf","w")
    for transcript_id in combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript:
        """
        whole_annotations[chromosome][transcript_id]={"exons":[],
                                                        "introns":[],
                                                        "cds":[],
                                                        "cds_frame":[],
                                                        "direction":direction,
                                                        "TPM":tpm,
                                                        "cov":cov,
                                                        "gene_id":gene_id,
                                                        "FPKM":fpkm,
                                                        "transcript_start":0,
                                                        "transcript_end":0,
                                                        "chromosome":chromosome
                                                        }
        """
        
        chromosome=combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript[transcript_id]["chromosome"]
        starting_exon=combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript[transcript_id]["exons"][0]
        last_exon=combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript[transcript_id]["exons"][-1]
        gene_id=combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript[transcript_id]["gene_id"]
        direction=combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript[transcript_id]["direction"]
        
        line=[chromosome,"PsiCLASS","exon",str(starting_exon[0]),str(starting_exon[0]+1),"1000",direction,".","gene_id \""+gene_id+"\"; transcript_id \""+transcript_id+"\""]
        fhw_first_and_last_exon.write("\t".join(line)+"\n")
        
        line=[chromosome,"PsiCLASS","exon",str(last_exon[1]-1),str(last_exon[1]),"1000",direction,".","gene_id \""+gene_id+"\"; transcript_id \""+transcript_id+"\""]
        fhw_first_and_last_exon.write("\t".join(line)+"\n")
    fhw_first_and_last_exon.close()
    
    cmd="bedtools subtract -A "
    cmd+=" -a <(bedtools subtract -a "+options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined_with_CDS_direction_fixed_to_modify_finder_whole_transcript.gtf"+" -b <(cat "+options.output_assemblies_psiclass_terminal_exon_length_modified+"/braker_to_modify_finder_CDS.gtf "+ options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined_with_CDS_direction_fixed_to_modify_finder_CDS.gtf ) ) "
    cmd+=" -b "+options.output_assemblies_psiclass_terminal_exon_length_modified+"/finder_first_and_last_exon_point.gtf "
    cmd+=" > "+options.output_assemblies_psiclass_terminal_exon_length_modified+"/exons_to_be_targeted.gtf"
    subprocess.check_call(['bash', '-c', cmd])
    
    #########################################################################################################################################
    
    return
                
    exons_to_be_targeted=readAllTranscriptsFromGTFFileInParallel([options.output_assemblies_psiclass_terminal_exon_length_modified+"/exons_to_be_targeted.gtf","dummy","dummy"])[0]
    FINDER_BRAKER_PROT=readAllTranscriptsFromGTFFileInParallel([psiclass_gtf_file,"dummy","dummy"])[0]
                                                                  
    #pprint.pprint(exons_to_be_targeted)
    sys.stdout.flush()
    add_these_transcripts={}
    remove_these_transcripts={}
    for chromosome in exons_to_be_targeted:
        for transcript_id in exons_to_be_targeted[chromosome]:
            if len(exons_to_be_targeted[chromosome][transcript_id]["exons"])==1:
                exon_start,exon_end=exons_to_be_targeted[chromosome][transcript_id]["exons"][0][0],exons_to_be_targeted[chromosome][transcript_id]["exons"][0][1]
                modified_exon_start,modified_exon_end=int((exon_start+exon_end)/2)-10,int((exon_start+exon_end)/2)+10
                print(transcript_id,chromosome+":"+str(int((exon_start+exon_end)/2-10))+"-"+str(int((exon_start+exon_end)/2+10)))
                for transcript_id_to_be_split in FINDER_BRAKER_PROT[chromosome]:
                    transcript_exon_start,transcript_exon_end=FINDER_BRAKER_PROT[chromosome][transcript_id_to_be_split]["transcript_start"],FINDER_BRAKER_PROT[chromosome][transcript_id_to_be_split]["transcript_end"]
                    if transcript_exon_start<=exon_start<=transcript_exon_end and transcript_exon_start<=exon_end<=transcript_exon_end:
                        
                        for exon in FINDER_BRAKER_PROT[chromosome][transcript_id_to_be_split]["exons"]:
                            if exon[0]<exon_start<exon[1] and exon[0]<exon_end<exon[1]:
                                #print(transcript_id_to_be_split,chromosome+":"+str(exon[0])+"-"+str(exon[1]))
                                FINDER_BRAKER_PROT[chromosome][transcript_id_to_be_split]
                                new_transcript_id_1=chromosome+"."+transcript_id_to_be_split.split(".")[1]+"_1b."+transcript_id_to_be_split.split(".")[-1]
                                new_transcript_id_2=chromosome+"."+transcript_id_to_be_split.split(".")[1]+"_2b."+transcript_id_to_be_split.split(".")[-1]
                                new_gene_id_1=".".join(new_transcript_id_1.split(".")[:2])
                                new_gene_id_2=".".join(new_transcript_id_2.split(".")[:2])
                                fill_transcript_id_1=1
                                direction=FINDER_BRAKER_PROT[chromosome][transcript_id_to_be_split]["direction"]
                                if chromosome not in add_these_transcripts:
                                    add_these_transcripts[chromosome]={}
                                add_these_transcripts[chromosome][new_transcript_id_1]={"exons":[],
                                                        "introns":[],
                                                        "cds":[],
                                                        "cds_frame":[],
                                                        "direction":direction,
                                                        "TPM":0,
                                                        "cov":0,
                                                        "gene_id":new_gene_id_1,
                                                        "FPKM":0,
                                                        "transcript_start":0,
                                                        "transcript_end":0,
                                                        "chromosome":chromosome}
                                for exon in FINDER_BRAKER_PROT[chromosome][transcript_id_to_be_split]["exons"]:
                                    if exon[0]<exon_start<exon[1] and exon[0]<exon_end<exon[1]:
                                        fill_transcript_id_1=0
                                        """if transcript_id_to_be_split=="1.3193_opp.0":
                                            print("Adjusting",chromosome+":"+str(exon_start)+"-"+str(exon_end))
                                            print("New Exon",chromosome+":"+str(exon[0])+"-"+str(int((exon_start+exon_end)/2)-10))
                                        
                                        if transcript_id_to_be_split=="1.3193_opp.0":
                                            print("Writing ",exon," to first split")"""
                                        add_these_transcripts[chromosome][new_transcript_id_1]["exons"].append([exon[0],int((exon_start+exon_end)/2)-10])
                                        #add_these_transcripts[chromosome][new_transcript_id_1]["exons"][-1][1]=int((exon_start+exon_end)/2)-10
                                        """if transcript_id_to_be_split=="1.3193_opp.0":
                                            pprint.pprint(add_these_transcripts[chromosome][new_transcript_id_1]["exons"])"""
                                        add_these_transcripts[chromosome][new_transcript_id_2]={"exons":[],
                                                        "introns":[],
                                                        "cds":[],
                                                        "cds_frame":[],
                                                        "direction":direction,
                                                        "TPM":0,
                                                        "cov":0,
                                                        "gene_id":new_gene_id_2,
                                                        "FPKM":0,
                                                        "transcript_start":0,
                                                        "transcript_end":0,
                                                        "chromosome":chromosome}
                                        if transcript_id_to_be_split=="1.3193_opp.0":
                                            print("Adjusting",chromosome+":"+str(exon_start)+"-"+str(exon_end))
                                            print("New Exon",chromosome+":"+str(int((exon_start+exon_end)/2)+10)+"-"+str(exon[1]))
                                        
                                        if transcript_id_to_be_split=="1.3193_opp.0":
                                            print("Writing ",exon," to second split")
                                        add_these_transcripts[chromosome][new_transcript_id_2]["exons"].append([int((exon_start+exon_end)/2)+10,exon[1]])
                                        #add_these_transcripts[chromosome][new_transcript_id_2]["exons"][0][0]=int((exon_start+exon_end)/2)+10
                                        continue
                                    if fill_transcript_id_1==1:
                                        if transcript_id_to_be_split=="1.3193_opp.0":
                                            print("Writing ",exon," to first split")
                                        add_these_transcripts[chromosome][new_transcript_id_1]["exons"].append(exon)
                                    else:
                                        if transcript_id_to_be_split=="1.3193_opp.0":
                                            print("Writing ",exon," to second split")
                                        add_these_transcripts[chromosome][new_transcript_id_2]["exons"].append(exon)
                                if chromosome not in remove_these_transcripts:
                                    remove_these_transcripts[chromosome]=[]
                                remove_these_transcripts[chromosome].append(transcript_id_to_be_split)
                                break
    """                        
    for chromosome in remove_these_transcripts:
        for transcript in remove_these_transcripts[chromosome]:
            del FINDER_BRAKER_PROT[chromosome][transcript]
    """
    for chromosome in add_these_transcripts:
        for transcript in add_these_transcripts[chromosome]:
            FINDER_BRAKER_PROT[chromosome][transcript]=add_these_transcripts[chromosome][transcript]
    writeTranscriptsToFile([FINDER_BRAKER_PROT,options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_with_CDS_models_fixed.gtf"])
    
def aggregateOutputFiles(options,logger_proxy,logging_mutex):
    """
    Aggregates all the output GTF files and puts them in one folder
    """
    options.final_GTF_files
    files_to_be_copied = [options.output_braker+"/braker.gtf", # BRAKER2 final GTF file
                          options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_redundant_transcripts_removed.gtf", # GTF file from PsiCLASS output
                          options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_split_transcripts_with_bad_SJ_redundancy_removed.gtf", # FINDER output without CDS
                          options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_with_CDS.gtf", # FINDER output with CDS
                          options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_with_CDS_low_conf.gtf", # Low confidence set
                          options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_with_CDS_high_conf.gtf", # High confidence set
                          options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_with_CDS_high_and_low_confidence_merged.gtf", # FINDER+BRAKER2+Protein
                          options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/combined_with_CDS_BRAKER_appended_high_conf.gtf", # High confidence set
                          options.output_assemblies_psiclass_terminal_exon_length_modified+"/combined/FINDER_BRAKER_PROT.gtf", # 
                          ]
    
    for file in files_to_be_copied:
        os.system(f"cp {file} {options.final_GTF_files}")
            
def main():
    commandLineArg=sys.argv
    if len(commandLineArg)==1:
        print("Please use the --help option to get usage information")
    options=parseCommandLineArguments()
    logger_proxy,logging_mutex=configureLogger(options)
    
    validateCommandLineArguments(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("validateCommandLineArguments execution successful")
    
    readMetaDataFile(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("readMetaDataFile execution successful")
    
    determineOptimalStartingPoint(options,logger_proxy,logging_mutex)
    
    orchestrateGeneModelPrediction(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("orchestrateGeneModelPrediction execution successful")
    
    configureAndRunBRAKER(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("BRAKER run completed")
    return
    findCDS(options)
    with logging_mutex:
        logger_proxy.info("Finding CDS completed")
    
    removeSpuriousTranscriptsBasedOnCDS(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("Sibling spurious transcripts removed")
    
    addBRAKERPredictions(options, logger_proxy, logging_mutex)  
    with logging_mutex:
        logger_proxy.info("Gene predictions and RNA-Seq evidence merged")
        
    aggregateOutputFiles(options,logger_proxy,logging_mutex)
    with logging_mutex:
        logger_proxy.info("Aggregating GTF files completed")
    

if __name__ == "__main__":
    main()
